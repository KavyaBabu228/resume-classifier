{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69635beb-57c9-47f4-af83-17bedf9b0bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "from flask import Flask, request, jsonify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a26c160-8d2b-4645-a1aa-75e20fb01217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Categories</th>\n",
       "      <th>Resume_Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>anubhav kumar singh core competency scripting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ananda rayudu profile summary year experience ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>peoplesoft database administrator gangareddy p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>classification internal classification interna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>priyanka ramadoss mountpleasant coonoor nilgir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3</td>\n",
       "      <td>workday integration consultant name sri krishn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>3</td>\n",
       "      <td>srikanth workday hcm consultant seeking suitab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>3</td>\n",
       "      <td>workday hcm fcm name kumar role workday consul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>3</td>\n",
       "      <td>venkateswarlu workday consultant professional ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>3</td>\n",
       "      <td>vinay kumar workday functional consultant expe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Categories                                     Resume_Details\n",
       "0            0  anubhav kumar singh core competency scripting ...\n",
       "1            0  ananda rayudu profile summary year experience ...\n",
       "2            0  peoplesoft database administrator gangareddy p...\n",
       "3            0  classification internal classification interna...\n",
       "4            0  priyanka ramadoss mountpleasant coonoor nilgir...\n",
       "..         ...                                                ...\n",
       "74           3  workday integration consultant name sri krishn...\n",
       "75           3  srikanth workday hcm consultant seeking suitab...\n",
       "76           3  workday hcm fcm name kumar role workday consul...\n",
       "77           3  venkateswarlu workday consultant professional ...\n",
       "78           3  vinay kumar workday functional consultant expe...\n",
       "\n",
       "[79 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = os.path.join(\"C:\\\\Users\\\\kavya\\\\Downloads\", \"cleaned_data.csv\")\n",
    "data = pd.read_csv(file_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "116b27e1-2697-4af6-b77f-b6da13f34d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Categories', 'Resume_Details'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9918da8d-7fd7-4325-8772-c601060c310d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 182)\t0.03136723387887679\n",
      "  (0, 1896)\t0.04261079090134825\n",
      "  (0, 3191)\t0.057309581492190065\n",
      "  (0, 777)\t0.026502338164750713\n",
      "  (0, 655)\t0.050475033080870806\n",
      "  (0, 3080)\t0.2271376488639186\n",
      "  (0, 3150)\t0.2271376488639186\n",
      "  (0, 193)\t0.22377127428567403\n",
      "  (0, 2499)\t0.3257953686482166\n",
      "  (0, 1543)\t0.07218894675237507\n",
      "  (0, 1326)\t0.039925934231947\n",
      "  (0, 2362)\t0.022000536212650496\n",
      "  (0, 1967)\t0.16099309120513047\n",
      "  (0, 3827)\t0.05123911626579028\n",
      "  (0, 3804)\t0.09571519762487549\n",
      "  (0, 187)\t0.06667377315213993\n",
      "  (0, 3123)\t0.3248502603856879\n",
      "  (0, 3805)\t0.14913776815471888\n",
      "  (0, 3622)\t0.14420395064457384\n",
      "  (0, 2812)\t0.04803567716691178\n",
      "  (0, 2378)\t0.11576677631483896\n",
      "  (0, 2915)\t0.04597323112877059\n",
      "  (0, 1441)\t0.06895984669315589\n",
      "  (0, 3842)\t0.009196297614892966\n",
      "  (0, 1449)\t0.028654790746095032\n",
      "  :\t:\n",
      "  (78, 3845)\t0.3722901561015264\n",
      "  (78, 2405)\t0.0292192126748219\n",
      "  (78, 710)\t0.1491454914460804\n",
      "  (78, 1111)\t0.20046393020851425\n",
      "  (78, 3862)\t0.0292192126748219\n",
      "  (78, 669)\t0.03730216571418394\n",
      "  (78, 3874)\t0.12188109388246281\n",
      "  (78, 466)\t0.0859131129465061\n",
      "  (78, 2484)\t0.031146123224850955\n",
      "  (78, 1575)\t0.03981058462353287\n",
      "  (78, 5)\t0.036214508232025856\n",
      "  (78, 2005)\t0.07242901646405171\n",
      "  (78, 3499)\t0.036214508232025856\n",
      "  (78, 3038)\t0.0685751953639936\n",
      "  (78, 3406)\t0.08256578647840151\n",
      "  (78, 126)\t0.042952059080678714\n",
      "  (78, 3500)\t0.03849355968789799\n",
      "  (78, 578)\t0.04715802108657991\n",
      "  (78, 2079)\t0.05354343102938969\n",
      "  (78, 2595)\t0.04994735463788267\n",
      "  (78, 1096)\t0.04715802108657991\n",
      "  (78, 2695)\t0.04715802108657991\n",
      "  (78, 695)\t0.04994735463788267\n",
      "  (78, 2421)\t0.05354343102938969\n",
      "  (78, 916)\t0.05354343102938969\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "     ..\n",
      "74    3\n",
      "75    3\n",
      "76    3\n",
      "77    3\n",
      "78    3\n",
      "Name: Categories, Length: 79, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming 'text' is the feature column and 'label' is the target\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X = tfidf.fit_transform(data['Resume_Details'])\n",
    "y = data['Categories']\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bfb622e-5c96-4791-8507-a42e68c81c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<63x3893 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 14432 stored elements in Compressed Sparse Row format>,\n",
       " <16x3893 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 3896 stored elements in Compressed Sparse Row format>,\n",
       " 73    3\n",
       " 61    3\n",
       " 55    2\n",
       " 40    1\n",
       " 9     0\n",
       "      ..\n",
       " 20    1\n",
       " 60    3\n",
       " 71    3\n",
       " 14    0\n",
       " 51    2\n",
       " Name: Categories, Length: 63, dtype: int64,\n",
       " 30    1\n",
       " 0     0\n",
       " 22    1\n",
       " 31    1\n",
       " 18    0\n",
       " 28    1\n",
       " 10    0\n",
       " 70    3\n",
       " 4     0\n",
       " 12    0\n",
       " 49    2\n",
       " 33    1\n",
       " 67    3\n",
       " 35    1\n",
       " 68    3\n",
       " 45    2\n",
       " Name: Categories, dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80d3a83b-4452-4905-9894-131a0e65d740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((63, 3893), (16, 3893), (63,), (16,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efdc968a-4829-42fa-aaf4-b6b49bd776fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the vectorizer on your resume data\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X = tfidf.fit_transform(data['Resume_Details'])  # Fit and transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04c45032-72c1-4b41-a7c5-f59ebd3ae045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# Fit the vectorizer on your resume text data\n",
    "X = vectorizer.fit_transform(data['Resume_Details'])\n",
    "\n",
    "# Save the trained vectorizer\n",
    "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
    "\n",
    "print(\"Trained vectorizer saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca335dae-2d4c-4b1f-9e68-5f9e29073831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_gradient_boosting.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameter grids\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "param_grid_dt = {\n",
    "    \"max_depth\": [10, 20, 30, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [10, 20, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "\n",
    "param_grid_gb = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"max_depth\": [3, 5, 10]\n",
    "}\n",
    "\n",
    "# Create models\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_dt = GridSearchCV(dt, param_grid_dt, cv=3, n_jobs=-1, verbose=1)\n",
    "grid_rf = GridSearchCV(rf, param_grid_rf, cv=3, n_jobs=-1, verbose=1)\n",
    "grid_gb = GridSearchCV(gb, param_grid_gb, cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit models\n",
    "grid_dt.fit(X_train, y_train)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "grid_gb.fit(X_train, y_train)\n",
    "\n",
    "# Get the best models\n",
    "best_dt = grid_dt.best_estimator_\n",
    "best_rf = grid_rf.best_estimator_\n",
    "best_gb = grid_gb.best_estimator_\n",
    "\n",
    "# Save the best models\n",
    "joblib.dump(best_dt, \"best_decision_tree.pkl\")\n",
    "joblib.dump(best_rf, \"best_random_forest.pkl\")\n",
    "joblib.dump(best_gb, \"best_gradient_boosting.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68cd0383-0424-45b1-8bf4-dd6ddfdde9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved successfully!\n",
      "✅ Vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Recreate the vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# Fit on your text data again\n",
    "vectorizer.fit(data['Resume_Details'])\n",
    "\n",
    "# Save the vectorizer\n",
    "joblib.dump(vectorizer, \"tfidf.pkl\")\n",
    "\n",
    "joblib.dump(grid_gb.best_estimator_, \"gradient_boosting.pkl\")\n",
    "\n",
    "print(\"✅ Model saved successfully!\")\n",
    "\n",
    "print(\"✅ Vectorizer saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9846bb84-5e47-4e3e-bc80-4f33d81a005d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Exists: True\n",
      "Model Exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"TF-IDF Exists:\", os.path.exists(\"tfidf.pkl\"))\n",
    "print(\"Model Exists:\", os.path.exists(\"gradient_boosting.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "49d61846-ae79-44b0-82ea-11e4250124c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model and vectorizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the vectorizer\n",
    "vectorizer = joblib.load(\"tfidf.pkl\")\n",
    "\n",
    "# Load the model\n",
    "best_model = joblib.load(\"gradient_boosting.pkl\")\n",
    "\n",
    "print(\"✅ Model and vectorizer loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f763b493-d7e9-47d9-9245-c80422692fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        24\n",
      "           2       1.00      1.00      1.00        14\n",
      "           3       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        79\n",
      "   macro avg       1.00      1.00      1.00        79\n",
      "weighted avg       1.00      1.00      1.00        79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform the test data using the loaded vectorizer\n",
    "X_test_tfidf = vectorizer.transform(data['Resume_Details'])  # Ensure correct input\n",
    "\n",
    "# Predict using the loaded model\n",
    "y_pred = best_model.predict(X_test_tfidf)\n",
    "\n",
    "# Print the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(data['Categories'], y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7663b7a3-a5ee-46f2-bf85-a81515b62b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
